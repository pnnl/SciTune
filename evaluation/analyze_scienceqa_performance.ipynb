{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import re\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sqa_dir='/qfs/projects/steel_thread/hora620/DevHub/scientific-instruction-tuning/ScienceQA/data/scienceqa/'\n",
    "problems = json.load(open(os.path.join(base_sqa_dir, \"problems.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_T=pd.DataFrame(problems).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which month is the wettest on average in Christchurch?',\n",
       " 'choices': ['August', 'April', 'May'],\n",
       " 'answer': 2,\n",
       " 'hint': 'Use the graph to answer the question below.',\n",
       " 'image': 'image.png',\n",
       " 'task': 'closed choice',\n",
       " 'grade': 'grade3',\n",
       " 'subject': 'natural science',\n",
       " 'topic': 'earth-science',\n",
       " 'category': 'Weather and climate',\n",
       " 'skill': 'Use climate data to make predictions',\n",
       " 'lecture': 'Scientists record climate data from places around the world. Precipitation, or rain and snow, is one type of climate data.\\nA bar graph can be used to show the average amount of precipitation each month. Months with taller bars have more precipitation on average.',\n",
       " 'solution': 'To describe the average precipitation trends in Christchurch, look at the graph.\\nChoice \"Apr\" is incorrect.\\nChoice \"May\" is incorrect.\\nChoice \"Aug\" is incorrect.\\nMay has an average monthly precipitation of about 70 millimeters. This is higher than in any other month. So, May is the wettest month on average.',\n",
       " 'split': 'test'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems['1526']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  90.02593727894364\n",
      "#Corrects: 3818/4241\n"
     ]
    }
   ],
   "source": [
    "# 7B + C-> \"/rcfs/projects/steel_thread/models/LLAVA-7b-pretrain-scitune-333472\"\n",
    "\n",
    "# 7B + CTOM -> \"/rcfs/projects/steel_thread/models/LLAVA-7b-pretrain-scitune-333472-v2\"\n",
    "\n",
    "# 13B + CTOM -> \"/rcfs/projects/steel_thread/models/LLAVA-7b-pretrain-scitune-333472-v2-13B\"\n",
    "\n",
    "# 13B-2 + CTOM -> \"/rcfs/projects/steel_thread/models/LLAVA-2-pretrain-scitune-333472-v2-13B\"\n",
    "\n",
    "base_model_dir='/rcfs/projects/steel_thread/models/LLAVA-7b-pretrain-scitune-333472-v2-13B'\n",
    "prediction_file='%s/scienceqa/llava_test_QCM-LEPA_prediction.jsonl'%base_model_dir\n",
    "predictions = [json.loads(line) for line in open(prediction_file)]\n",
    "\n",
    "results_file='%s/scienceqa/llava_test_QCM-LEPA_prediction_result.jsonl'%base_model_dir\n",
    "results=json.load(open(results_file,'r'))\n",
    "print('Accuracy: ',results['acc'])\n",
    "print('#Corrects: %d/%d'%(results['correct'],results['count']))\n",
    "\n",
    "results_outputs_file='%s/scienceqa/llava_test_QCM-LEPA_prediction_output.jsonl'%base_model_dir\n",
    "results_outputs=json.load(open(results_outputs_file,'r'))\n",
    "results_outputs_0=pd.DataFrame(results_outputs['correct']).set_index('question_id')\n",
    "results_outputs_0['accuracy_label']='correct'\n",
    "results_outputs_1=pd.DataFrame(results_outputs['incorrect']).set_index('question_id')\n",
    "results_outputs_1['accuracy_label']='incorrect'\n",
    "results_outputs=pd.concat([results_outputs_0,results_outputs_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsed_ans</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>question</th>\n",
       "      <th>pred</th>\n",
       "      <th>is_multimodal</th>\n",
       "      <th>accuracy_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Which figure of speech is used in this text?\\n...</td>\n",
       "      <td>Assistant: LECTURE: Figures of speech are word...</td>\n",
       "      <td>False</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Which of the following could Gordon's test sho...</td>\n",
       "      <td>Assistant: LECTURE: People can use the enginee...</td>\n",
       "      <td>True</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>What is the name of the colony shown?\\nContext...</td>\n",
       "      <td>Assistant: SOLUTION: The colony is New Hampshi...</td>\n",
       "      <td>True</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Would you find the word dozen on a dictionary ...</td>\n",
       "      <td>Assistant: LECTURE: Guide words appear on each...</td>\n",
       "      <td>False</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Which of these organisms contains matter that ...</td>\n",
       "      <td>Assistant: LECTURE: A food web is a model.\\nA ...</td>\n",
       "      <td>True</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            parsed_ans ground_truth  \\\n",
       "question_id                           \n",
       "4                    B            B   \n",
       "5                    B            B   \n",
       "11                   B            B   \n",
       "15                   A            A   \n",
       "23                   B            B   \n",
       "\n",
       "                                                      question  \\\n",
       "question_id                                                      \n",
       "4            Which figure of speech is used in this text?\\n...   \n",
       "5            Which of the following could Gordon's test sho...   \n",
       "11           What is the name of the colony shown?\\nContext...   \n",
       "15           Would you find the word dozen on a dictionary ...   \n",
       "23           Which of these organisms contains matter that ...   \n",
       "\n",
       "                                                          pred  is_multimodal  \\\n",
       "question_id                                                                     \n",
       "4            Assistant: LECTURE: Figures of speech are word...          False   \n",
       "5            Assistant: LECTURE: People can use the enginee...           True   \n",
       "11           Assistant: SOLUTION: The colony is New Hampshi...           True   \n",
       "15           Assistant: LECTURE: Guide words appear on each...          False   \n",
       "23           Assistant: LECTURE: A food web is a model.\\nA ...           True   \n",
       "\n",
       "            accuracy_label  \n",
       "question_id                 \n",
       "4                  correct  \n",
       "5                  correct  \n",
       "11                 correct  \n",
       "15                 correct  \n",
       "23                 correct  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question=\"Which month is the wettest on average in Christchurch?\"\n",
    "X=results_outputs[results_outputs['question'].str.match(sample_question)]#.iloc[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: LECTURE: Scientists record climate data from places around the world. Precipitation, or rain and snow, is one type of climate data. Scientists collect data over many years. They can use this data to calculate the average precipitation for each month. The average precipitation can be used to describe the climate of a location.\n",
      "A bar graph can be used to show the average amount of precipitation each month. Months with taller bars have more precipitation on average.\n",
      "SOLUTION: To describe the average precipitation trends in Christchurch, look at the graph.\n",
      "Choice \"Apr\" is incorrect.\n",
      "Choice \"May\" is incorrect.\n",
      "Choice \"Aug\" is incorrect.\n",
      "May has an average monthly precipitation of about 70 millimeters. This is higher than in any other month. So, May is the wettest month on average.\n",
      " The answer is C.\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[0]['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_results_file='./llava/eval/table/results/test_sqa_llava_13b_v0.json'\n",
    "llava_results=json.load(open(llava_results_file,'r'))\n",
    "print('LLaVA Accuracy: ',llava_results['acc'])\n",
    "print('#Corrects: %d/%d'%(llava_results['correct'],llava_results['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_results_outputs=pd.DataFrame(llava_results['outputs'].items(),columns=['question_id','predictions'])#.set_index('question_id')\n",
    "\n",
    "def get_pred_idx(prediction, choices):\n",
    "    \"\"\"\n",
    "    Get the index (e.g. 2) from the prediction (e.g. 'C')\n",
    "    \"\"\"\n",
    "    options=[\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "    if prediction in options[:len(choices)]:\n",
    "        return options.index(prediction)\n",
    "    else:\n",
    "        return random.choice(range(len(choices)))\n",
    "    \n",
    "def get_pred_label(row):\n",
    "    pred_text=row['predictions']\n",
    "    q_id=row['question_id']\n",
    "    pattern = re.compile(r'The answer is ([A-Z]).')\n",
    "    res = pattern.findall(pred_text)\n",
    "    if len(res) == 1:\n",
    "        answer = res[0]  # 'A', 'B', ...\n",
    "    else:\n",
    "        answer = \"FAILED\"\n",
    "\n",
    "    return get_pred_idx(answer,problems[q_id]['choices'])\n",
    "\n",
    "  \n",
    "llava_results_outputs['gt_answer_index']=llava_results_outputs.apply(lambda x: problems[x['question_id']]['answer'],axis=1)                   \n",
    "llava_results_outputs['pred_answer_index']=llava_results_outputs.apply(get_pred_label,axis=1)\n",
    "llava_results_outputs.set_index('question_id',inplace=True)\n",
    "\n",
    "# llava_results_outputs_1=pd.DataFrame(llava_results['results'].items(),columns=['question_id','gt_answer_index']).set_index('question_id')\n",
    "\n",
    "# llava_results_outputs=pd.merge(llava_results_outputs_0,llava_results_outputs_1,left_index=True, right_index=True)\n",
    "\n",
    "llava_results_outputs['accuracy_index']=0\n",
    "llava_results_outputs.loc[llava_results_outputs['pred_answer_index']==llava_results_outputs['gt_answer_index'],'accuracy_index']=1\n",
    "\n",
    "\n",
    "\n",
    "llava_results_outputs_with_metadata=pd.merge(llava_results_outputs,problems_T,how='inner',left_index=True,right_index=True)\n",
    "\n",
    "print(\"LLaVA Accuracy (Global): \",llava_results_outputs_with_metadata['accuracy_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_results_outputs_with_metadata.head()#loc['4']['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which month is the wettest on average in Christchurch?',\n",
       " 'choices': ['August', 'April', 'May'],\n",
       " 'answer': 2,\n",
       " 'hint': 'Use the graph to answer the question below.',\n",
       " 'image': 'image.png',\n",
       " 'task': 'closed choice',\n",
       " 'grade': 'grade3',\n",
       " 'subject': 'natural science',\n",
       " 'topic': 'earth-science',\n",
       " 'category': 'Weather and climate',\n",
       " 'skill': 'Use climate data to make predictions',\n",
       " 'lecture': 'Scientists record climate data from places around the world. Precipitation, or rain and snow, is one type of climate data.\\nA bar graph can be used to show the average amount of precipitation each month. Months with taller bars have more precipitation on average.',\n",
       " 'solution': 'To describe the average precipitation trends in Christchurch, look at the graph.\\nChoice \"Apr\" is incorrect.\\nChoice \"May\" is incorrect.\\nChoice \"Aug\" is incorrect.\\nMay has an average monthly precipitation of about 70 millimeters. This is higher than in any other month. So, May is the wettest month on average.',\n",
       " 'split': 'test'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_id=\"1526\"\n",
    "# print(\"Generated Answer: \",results['outputs'][question_id])\n",
    "# print(\"Answer Index: \",results['results'][question_id])\n",
    "#display(results_outputs.loc[question_id])\n",
    "\n",
    "problems[question_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_problems=[]\n",
    "# for question_id in problems.keys():\n",
    "    \n",
    "#     test_problem=problems[question_id]\n",
    "#     if test_problem['split']==\"test\":\n",
    "#         test_problem.setdefault(\"question_id\",question_id)\n",
    "#         test_problem.setdefault(\"prediction\",results_outputs.loc[question_id]['pred'])\n",
    "#         test_problem.setdefault(\"accuracy_label\",results_outputs.loc[question_id]['accuracy_label'])\n",
    "#         test_problems.append(test_problem)\n",
    "\n",
    "# # ## Optional; saved the javascript array for demo\n",
    "# # import json\n",
    "# # with open('test_problems.js', 'w') as fout:\n",
    "# #     json.dump(test_problems, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Question:\\t%s\\n\"%results_outputs.loc[question_id]['question'])\n",
    "print(\"Prediction:\\t%s\\n\"%results_outputs.loc[question_id]['pred'])\n",
    "\n",
    "print(\"Answer (parsed)\\t%s\\n\"%results_outputs.loc[question_id]['parsed_ans'])\n",
    "print(\"Answer (GT)\\t%s\\n\"%results_outputs.loc[question_id]['ground_truth'])\n",
    "\n",
    "print(\"Is Multimodal:\\t%s\\n\"%results_outputs.loc[question_id]['is_multimodal'])\n",
    "print(\"Accuracy Label:\\t%s\\n\"%results_outputs.loc[question_id]['accuracy_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sel_q=\"Which trait did Palaeopython have?\"\n",
    "# sel_records=results_outputs_with_metadata[results_outputs_with_metadata['question_x'].str.contains(sel_q)]#.query('question_x==@sel_q')\n",
    "# sel_records.index=sel_records.index.astype(str)\n",
    "# sel_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_q_id='2005'\n",
    "print(sel_records.loc[[sel_q_id]]['question_x'].iloc[0])\n",
    "\n",
    "print(sel_records.loc[[sel_q_id]]['choices'].iloc[0])\n",
    "print(sel_records.loc[[sel_q_id]]['lecture'].iloc[0])\n",
    "\n",
    "print(sel_records.loc[[sel_q_id]]['pred'].iloc[0])\n",
    "print(sel_records.loc[[sel_q_id]]['accuracy_label'].iloc[0])\n",
    "\n",
    "\n",
    "print(\"\\n\\n## LLaVA\")\n",
    "print(\"\",llava_results['outputs'][sel_q_id])\n",
    "image = Image.open(os.path.join(base_sqa_dir, 'images/test/%s/image.png'%sel_q_id)).convert('RGB')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/qfs/projects/steel_thread/hora620/DevHub/scientific-instruction-tuning/ScienceQA/data/scienceqa/images/val/1526/image.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/qfs/projects/steel_thread/hora620/DevHub/scientific-instruction-tuning/LLaVA/analyze_scienceqa_performance.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdeception/qfs/projects/steel_thread/hora620/DevHub/scientific-instruction-tuning/LLaVA/analyze_scienceqa_performance.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(base_sqa_dir, \u001b[39m'\u001b[39;49m\u001b[39mimages/val/\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m/image.png\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49mquestion_id))\u001b[39m.\u001b[39mconvert(\u001b[39m'\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeception/qfs/projects/steel_thread/hora620/DevHub/scientific-instruction-tuning/LLaVA/analyze_scienceqa_performance.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m image\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/PIL/Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3224\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   3226\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3227\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   3228\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3230\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/qfs/projects/steel_thread/hora620/DevHub/scientific-instruction-tuning/ScienceQA/data/scienceqa/images/val/1526/image.png'"
     ]
    }
   ],
   "source": [
    "image = Image.open(os.path.join(base_sqa_dir, 'images/val/%s/image.png'%question_id)).convert('RGB')\n",
    "image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMA-SciTune Performance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_outputs_with_metadata=pd.merge(results_outputs,problems_T,how='inner',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_outputs_with_metadata['accuracy_index']=0\n",
    "results_outputs_with_metadata.loc[results_outputs_with_metadata['accuracy_label']==\"correct\",'accuracy_index']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Global):  0.821032775288847\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (Global): \",results_outputs_with_metadata['accuracy_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Global):  is_multimodal\n",
      "False    0.881745\n",
      "True     0.754090\n",
      "Name: accuracy_index, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (Global): \",results_outputs_with_metadata.groupby('is_multimodal')['accuracy_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Global):  subject\n",
      "language science    0.835455\n",
      "natural science     0.838366\n",
      "social science      0.759280\n",
      "Name: accuracy_index, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (Global): \",results_outputs_with_metadata.groupby('subject')['accuracy_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Global):  grade\n",
      "grade1     0.705882\n",
      "grade10    0.815126\n",
      "grade11    0.828571\n",
      "grade12    0.906977\n",
      "grade2     0.819113\n",
      "grade3     0.846395\n",
      "grade4     0.855869\n",
      "grade5     0.824534\n",
      "grade6     0.799564\n",
      "grade7     0.803887\n",
      "grade8     0.739884\n",
      "grade9     0.942623\n",
      "Name: accuracy_index, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy (Global): \",results_outputs_with_metadata.groupby('grade')['accuracy_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (G1-6):  0.8085596065159736\n",
      "Accuracy (G7-12):  0.8395114154759918\n"
     ]
    }
   ],
   "source": [
    "sel_grades=['grade1','grade2','grade3','grade4','grade5','grade6']\n",
    "print(\"Accuracy (G1-6): \",results_outputs_with_metadata.groupby('grade')['accuracy_index'].mean()[sel_grades].mean())\n",
    "\n",
    "sel_grades=['grade7','grade8','grade9','grade10','grade11','grade12']\n",
    "print(\"Accuracy (G7-12): \",results_outputs_with_metadata.groupby('grade')['accuracy_index'].mean()[sel_grades].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Context):  is_context\n",
      "False    0.824146\n",
      "True     0.817693\n",
      "Name: accuracy_index, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_outputs_with_metadata['is_context']=~results_outputs_with_metadata['question_x'].str.contains('Context: N/A')\n",
    "print(\"Accuracy (Context): \",results_outputs_with_metadata.groupby('is_context')['accuracy_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_results_outputs_with_metadata.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMA SciTune vs. LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sel_cols=['predictions','gt_answer_index','pred_answer_index',]\n",
    "llava_scitune_results_outputs=pd.merge(results_outputs_with_metadata[['accuracy_index']],llava_results_outputs_with_metadata[['accuracy_index']],left_index=True,right_index=True,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scitune_top=llava_scitune_results_outputs[(llava_scitune_results_outputs['accuracy_index_x']==1) & (llava_scitune_results_outputs['accuracy_index_y']==0)]\n",
    "scitune_top_with_metadata=pd.merge(scitune_top,problems_T,how='inner',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_top=llava_scitune_results_outputs[(llava_scitune_results_outputs['accuracy_index_x']==0) & (llava_scitune_results_outputs['accuracy_index_y']==1)]\n",
    "llava_top_with_metadata=pd.merge(llava_top,problems_T,how='inner',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scitune_top_with_metadata.groupby('skill').size().sort_values(ascending=False)#head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_top_with_metadata.groupby('skill').size().sort_values(ascending=False)#head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
